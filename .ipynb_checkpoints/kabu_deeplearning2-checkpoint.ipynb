{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 2. 0.]\n",
      " [0. 3. 0.]\n",
      " [0. 4. 0.]\n",
      " [0. 5. 0.]\n",
      " [0. 6. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import *\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import mglearn\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "import os\n",
    "import glob\n",
    "\n",
    "t=np.zeros((6,3))\n",
    "t[0:6, 1]=[1,2,3,4,5,6]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.\\\\6501TimeChart.csv', '.\\\\6645TimeChart.csv', '.\\\\6752TimeChart.csv', '.\\\\6758TimeChart.csv', '.\\\\6856TimeChart.csv', '.\\\\7701TimeChart.csv']\n",
      "[[20020109 4805.0 4845.0 ... '         --' '         --' 877000]\n",
      " [20020110 4820.0 4830.0 ... '         --' '         --' 882600]\n",
      " [20020111 4805.0 4815.0 ... '         --' '         --' 1173800]\n",
      " ...\n",
      " [20191226 4599.0 4621.0 ... '    4350.16' '       4186' 1706000]\n",
      " [20191227 4623.0 4640.0 ... '    4370.88' '    4195.16' 1632100]\n",
      " [20191230 4606.0 4636.0 ... '     4390.8' '       4204' 2303600]]\n",
      "[[20020115 279 280 ... '         --' '         --' 727000]\n",
      " [20020116 271 272 ... '         --' '         --' 389000]\n",
      " [20020117 266 267 ... '         --' '         --' 416000]\n",
      " ...\n",
      " [20191226 3480 3490 ... '     3363.8' '    3023.76' 264400]\n",
      " [20191227 3500 3505 ... '       3375' '     3034.9' 325300]\n",
      " [20191230 3495 3495 ... '     3382.6' '    3045.36' 399900]]\n",
      "[[20020109 1767.0 1795.0 ... '         --' '         --' 10014000]\n",
      " [20020110 1790.0 1815.0 ... '         --' '         --' 8181000]\n",
      " [20020111 1721.0 1742.0 ... '         --' '         --' 16328000]\n",
      " ...\n",
      " [20191226 1009.5 1018.5 ... '    1024.91' '     958.04' 3056200]\n",
      " [20191227 1021.0 1034.5 ... '    1026.52' '     960.44' 4756600]\n",
      " [20191230 1029.0 1032.0 ... '    1028.99' '     962.81' 5054700]]\n",
      "[[20020109 6350.0 6450.0 ... '         --' '         --' 3671300]\n",
      " [20020110 6440.0 6700.0 ... '         --' '         --' 7831200]\n",
      " [20020111 6520.0 6550.0 ... '         --' '         --' 3773600]\n",
      " ...\n",
      " [20191226 7399.0 7440.0 ... '    7179.56' '    6699.89' 2297900]\n",
      " [20191227 7450.0 7482.0 ... '    7210.12' '    6714.42' 3597500]\n",
      " [20191230 7421.0 7423.0 ... '    7237.64' '    6726.49' 4512200]]\n",
      "[[20020115 911 920 ... '         --' '         --' 7000]\n",
      " [20020116 920 925 ... '         --' '         --' 71000]\n",
      " [20020117 931 940 ... '         --' '         --' 107000]\n",
      " ...\n",
      " [20191226 7410 7520 ... '       7452' '       6996' 88500]\n",
      " [20191227 7470 7470 ... '       7462' '     7018.4' 89800]\n",
      " [20191230 7410 7420 ... '     7466.8' '    7037.73' 113500]]\n",
      "[[20020115 279 280 ... '         --' '         --' 727000]\n",
      " [20020116 271 272 ... '         --' '         --' 389000]\n",
      " [20020117 266 267 ... '         --' '         --' 416000]\n",
      " ...\n",
      " [20191226 3480 3490 ... '     3363.8' '    3023.76' 264400]\n",
      " [20191227 3500 3505 ... '       3375' '     3034.9' 325300]\n",
      " [20191230 3495 3495 ... '     3382.6' '    3045.36' 399900]]\n",
      "y_1: [1.03058511 1.0541272  1.04470939 ... 1.03816199 1.04770256 1.03392569]\n",
      "X.shape:  (25826, 24)\n",
      "yの割合\n",
      "0.0    24088\n",
      "1.0     1738\n",
      "Name: 0, dtype: int64\n",
      "X_.shape:  (3906, 24)\n",
      "y_の割合\n",
      "0.0    2168\n",
      "1.0    1738\n",
      "Name: 0, dtype: int64\n",
      "X_train: [[1.00277778 1.         1.01123596 ... 0.86632718 0.70314423 1.11060022]\n",
      " [0.985138   0.98329854 0.99377593 ... 0.89304664 1.03437319 1.58698143]\n",
      " [1.00718563 0.92777778 1.05140187 ... 0.81832379 0.49792639 1.31001698]\n",
      " ...\n",
      " [0.97864769 0.98481308 0.98845266 ... 1.09585703 0.8724309  1.14158576]\n",
      " [1.00495868 1.00833333 0.99833611 ... 0.98890411 0.73789548 0.91070607]\n",
      " [0.98684211 1.         1.00662252 ... 1.10159363 1.06131078 1.33114447]]\n",
      "start time:  17:37:10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([1.00415512, 1.00215517, 1.05172414, ..., 1.03636364, 0.97039474,\n       1.00666667]),)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6be1245cc672>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'classifier__hidden_layer_sizes'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[0mmlp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMLPClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"accuracy on test set:{:.3f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\keras35\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    971\u001b[0m         \"\"\"\n\u001b[0;32m    972\u001b[0m         return self._fit(X, y, incremental=(self.warm_start and\n\u001b[1;32m--> 973\u001b[1;33m                                             hasattr(self, \"classes_\")))\n\u001b[0m\u001b[0;32m    974\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\keras35\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    329\u001b[0m                              hidden_layer_sizes)\n\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\keras35\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36m_validate_input\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    914\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 916\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    917\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\keras35\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_input_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\keras35\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: (array([1.00415512, 1.00215517, 1.05172414, ..., 1.03636364, 0.97039474,\n       1.00666667]),)"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "# 上場企業４２３社の２０年分を学習\n",
    "# 終値前日比1.03%以上であるかを２クラス分類\n",
    "# データ比１１：１を１：１に調整（減らした）\n",
    "# StandardScaler accuracy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import *\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import mglearn\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# 実行上問題ない注意は非表示にする\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# data/kabu1フォルダ内にあるcsvファイルの一覧を取得\n",
    "files = glob.glob(\"./*.csv\")\n",
    "print(files)\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# 説明変数となる行列X, 被説明変数となるy2を作成\n",
    "base = 100 \n",
    "day_ago = 3\n",
    "num_sihyou = 8\n",
    "reset =True\n",
    "# すべてのCSVファイルから得微量作成\n",
    "for file in files:\n",
    "    temp = pd.read_csv(file, header=0, encoding='cp932')\n",
    "    temp = temp[['日付','始値', '高値','安値','終値','5日平均','25日平均','75日平均','出来高']]\n",
    "    temp= temp.iloc[::-1]#上下反対に\n",
    "    temp2 = np.array(temp)\n",
    "    print(temp2)\n",
    "    # 前日比を出すためにbase日後からのデータを取得\n",
    "    temp3 = np.zeros((len(temp2)-base, num_sihyou))\n",
    "    temp3[0:len(temp3), 0] = temp2[base:len(temp2), 4] / temp2[base-1:len(temp2)-1, 4]\n",
    "    temp3[0:len(temp3), 1] = temp2[base:len(temp2), 1] / temp2[base:len(temp2), 4]\n",
    "    temp3[0:len(temp3), 2] = temp2[base:len(temp2), 2] / temp2[base:len(temp2), 4]\n",
    "    temp3[0:len(temp3), 3] = temp2[base:len(temp2), 3] / temp2[base:len(temp2), 4]\n",
    "    temp3[0:len(temp3), 4] = temp2[base:len(temp2), 5].astype(np.float) / temp2[base:len(temp2), 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 5] = temp2[base:len(temp2), 6].astype(np.float) / temp2[base:len(temp2), 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 6] = temp2[base:len(temp2), 7].astype(np.float) / temp2[base:len(temp2), 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 7] = temp2[base:len(temp2), 8].astype(np.float) / temp2[base-1:len(temp2)-1, 8].astype(np.float)\n",
    "    \n",
    "    # tempX : 現在の企業のデータ\n",
    "    tempX = np.zeros((len(temp3), day_ago*num_sihyou))\n",
    "    \n",
    "    # 日にちごとに横向きに（day_ago）分並べる\n",
    "    # sckit-learnは過去の情報を学習できないので、複数日（day_ago）分を特微量に加える必要がある\n",
    "    # 注：tempX[0:day_ago]分は欠如データが生まれる\n",
    "    for s in range(0, num_sihyou): \n",
    "        for i in range(0, day_ago):\n",
    "            tempX[i:len(temp3), day_ago*s+i] = temp3[0:len(temp3)-i,s]\n",
    "             \n",
    "    # Xに追加\n",
    "    # X : すべての企業のデータ\n",
    "    # tempX[0:day_ago]分は削除\n",
    "    if reset:\n",
    "        X = tempX[day_ago:]\n",
    "        reset = False\n",
    "    else:\n",
    "        X = np.concatenate((X, tempX[day_ago:]), axis=0)\n",
    "\n",
    "# 何日後を値段の差を予測するのか\n",
    "pre_day = 1\n",
    "# y : pre_day後の終値/当日終値\n",
    "y = np.zeros(len(X))\n",
    "y[0:len(y)-pre_day] = X[pre_day:len(X),0]\n",
    "X = X[:-pre_day]\n",
    "y = y[:-pre_day]\n",
    "\n",
    "up_rate =1.03\n",
    "\n",
    "# データを一旦分別\n",
    "X_0 = X[y<=up_rate]\n",
    "X_1 = X[y>up_rate]\n",
    "y_0 = y[y<=up_rate]\n",
    "y_1 = y[y>up_rate]\n",
    "print(\"y_1:\",y_1)\n",
    "\n",
    "# X_0をX_1とほぼ同じ数にする\n",
    "X_drop, X_t, y_drop, y_t = train_test_split(X_0, y_0, test_size=0.09, random_state=0)\n",
    "\n",
    "# 分別したデータの結合\n",
    "X_ = np.concatenate((X_1, X_t), axis=0)\n",
    "y_ = np.concatenate((y_1, y_t))\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "# 確認\n",
    "# 何もしないときの比率\n",
    "print(\"X.shape: \", X.shape)\n",
    "\n",
    "print(\"yの割合\")\n",
    "# yc：翌日の終値/当日の終値がup_rateより上か\n",
    "yc = np.zeros(len(y))\n",
    "for i in range(0, len(yc)):\n",
    "    if y[i] <= up_rate:\n",
    "        yc[i] = 0\n",
    "    else:\n",
    "        yc[i] = 1\n",
    "\n",
    "pd_yc = pd.DataFrame(yc)\n",
    "print(pd_yc[0].value_counts())\n",
    "\n",
    "# 確認\n",
    "# X_0をX_1の数を調整後の比率\n",
    "print(\"X_.shape: \", X_.shape)\n",
    "\n",
    "print(\"y_の割合\")\n",
    "# yc：翌日の終値/当日の終値がup_rateより上か\n",
    "yc_ = np.zeros(len(y_))\n",
    "for i in range(0, len(yc_)):\n",
    "    if y_[i] <= up_rate:\n",
    "        yc_[i] = 0\n",
    "    else:\n",
    "        yc_[i] = 1\n",
    "\n",
    "pd_yc_ = pd.DataFrame(yc_)\n",
    "print(pd_yc_[0].value_counts())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y_, random_state=0)\n",
    "print(\"X_train:\", X_train)\n",
    "# y_train_,y_test2：翌日の終値/当日の終値がup_rateより上か\n",
    "y_train2 = np.zeros(len(y_train))\n",
    "for i in range(0, len(y_train2)):\n",
    "    if y_train[i] <= up_rate:\n",
    "        y_train2[i] = 0\n",
    "    else:\n",
    "        y_train2[i] = 1\n",
    "        \n",
    "y_test2 = np.zeros(len(y_test))\n",
    "for i in range(0, len(y_test2)):\n",
    "    if y_test[i] <= up_rate:\n",
    "        y_test2[i] = 0\n",
    "    else:\n",
    "        y_test2[i] = 1\n",
    "\n",
    "print(\"start time: \", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('classifier', MLPClassifier(max_iter=200000, alpha=0.001))])\n",
    "param_grid = {'classifier__hidden_layer_sizes': [(10,), (100,), (500,)]}\n",
    "mlp=MLPClassifier(max_iter=200000, alpha=0.001,random_state=0)\n",
    "mlp.fit(X_train,y_train)\n",
    "print(\"accuracy on test set:{:.3f}\".format(mlp.score(X_test,y_test)))\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, n_jobs=1, cv=2 ,return_train_score=False, scoring=\"accuracy\")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.cv_results_['mean_test_score'])\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"grid best score, \", grid.best_score_)\n",
    "print(\"Test set score: {:.2f}\".format(grid.score(X_test, y_test)))\n",
    "print(\"over time: \", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "conf = confusion_matrix(y_test, grid.predict(X_test))\n",
    "print(conf)\n",
    "\n",
    "\n",
    "# 一目均衡表,転換線,基準線,先行スパン1,先行スパン2,25日ボリンジャーバンド, 曜日 追加\n",
    "# 説明変数となる行列X, 被説明変数となるy2を作成\n",
    "base = 100 \n",
    "day_ago = 3\n",
    "num_sihyou = 16\n",
    "reset =True\n",
    "# すべてのCSVファイルから得微量作成\n",
    "for file in files:\n",
    "    temp = pd.read_csv(file, header=0, encoding='cp932')\n",
    "    temp = temp[['日付','始値', '高値','安値','終値','5日平均','25日平均','75日平均','出来高']]\n",
    "    temp= temp.iloc[::-1]#上下反対に\n",
    "    temp2 = np.array(temp)\n",
    "    \n",
    "    # 前日比を出すためにbase日後からのデータを取得\n",
    "    temp3 = np.zeros((len(temp2)-base, num_sihyou))\n",
    "    temp3[0:len(temp3), 0] = temp2[base:len(temp2), 4] / temp2[base-1:len(temp2)-1, 4]\n",
    "    temp3[0:len(temp3), 1] = temp2[base:len(temp2), 1] / temp2[base:len(temp2), 4]\n",
    "    temp3[0:len(temp3), 2] = temp2[base:len(temp2), 2] / temp2[base:len(temp2), 4]\n",
    "    temp3[0:len(temp3), 3] = temp2[base:len(temp2), 3] / temp2[base:len(temp2), 4]\n",
    "    temp3[0:len(temp3), 4] = temp2[base:len(temp2), 5].astype(np.float) / temp2[base:len(temp2), 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 5] = temp2[base:len(temp2), 6].astype(np.float) / temp2[base:len(temp2), 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 6] = temp2[base:len(temp2), 7].astype(np.float) / temp2[base:len(temp2), 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 7] = temp2[base:len(temp2), 8].astype(np.float) / temp2[base-1:len(temp2)-1, 8].astype(np.float)\n",
    "    \n",
    "     # 一目均衡表を追加します (9,26, 52) \n",
    "    para1 =9\n",
    "    para2 = 26\n",
    "    para3 = 52\n",
    "    temp2_2 = np.c_[temp2, np.zeros((len(temp2), 3))]\n",
    "    p1 = 9\n",
    "    p2 = 10\n",
    "    p3 =11\n",
    "    \n",
    "    # 転換線 = （過去(para1)日間の高値 + 安値） ÷ 2\n",
    "    for i in range(para1, len(temp2)):\n",
    "        tmp_high =temp2[i-para1+1:i+1,2].astype(np.float)\n",
    "        tmp_low =temp2[i-para1+1:i+1,3].astype(np.float)\n",
    "        temp2_2[i, p1] = (np.max(tmp_high) + np.min(tmp_low)) / 2 /temp2[i, 4]\n",
    "        \n",
    "    temp3[0:len(temp3), 8] = temp2_2[base:len(temp2), p1]\n",
    "\n",
    "    # 基準線 = （過去(para2)日間の高値 + 安値） ÷ 2\n",
    "    for i in range(para2, len(temp2)):\n",
    "        tmp_high =temp2[i-para2+1:i+1,2].astype(np.float)\n",
    "        tmp_low =temp2[i-para2+1:i+1,3].astype(np.float)\n",
    "        temp2_2[i, p2] = (np.max(tmp_high) + np.min(tmp_low)) / 2 /temp2[i, 4]\n",
    "    temp3[0:len(temp3), 9] = temp2_2[base:len(temp2), p2]\n",
    "        \n",
    "\n",
    "    # 先行スパン1 = ｛ （転換値+基準値） ÷ 2 ｝を(para2)日先にずらしたもの\n",
    "    temp3[0:len(temp3), 10] = (temp2_2[base-para2:len(temp2)-para2, p1] + temp2_2[base-para2:len(temp2)-para2, p2]) /2 /temp2[base:len(temp2), 4]\n",
    "\n",
    "    # 先行スパン2 = ｛ （過去(para3)日間の高値+安値） ÷ 2 ｝を(para2)日先にずらしたもの\n",
    "    for i in range(para3, len(temp2)):\n",
    "        tmp_high =temp2[i-para3+1:i+1,2].astype(np.float)\n",
    "        tmp_low =temp2[i-para3+1:i+1,3].astype(np.float)\n",
    "        temp2_2[i, p3] = (np.max(tmp_high) + np.min(tmp_low)) / 2 /temp2[i, 4]\n",
    "    temp3[0:len(temp3), 11] = temp2_2[base-para2:len(temp2)-para2, p3]\n",
    "\n",
    "    # 25日ボリンジャーバンド（±1, 2シグマ）を追加します\n",
    "    parab = 25\n",
    "    for i in range(base, len(temp2)):\n",
    "        tmp25 = temp2[i-parab+1:i+1,4].astype(np.float)\n",
    "        temp3[i-base,12] = np.mean(tmp25) + 1.0* np.std(tmp25) \n",
    "        temp3[i-base,13] = np.mean(tmp25) - 1.0* np.std(tmp25) \n",
    "        temp3[i-base,14] = np.mean(tmp25) + 2.0* np.std(tmp25) \n",
    "        temp3[i-base,15] = np.mean(tmp25) - 2.0* np.std(tmp25)\n",
    "        \n",
    "    # tempX : 現在の企業のデータ\n",
    "    tempX = np.zeros((len(temp3), day_ago*num_sihyou))\n",
    "    \n",
    "    # 日にちごとに横向きに（day_ago）分並べる\n",
    "    # sckit-learnは過去の情報を学習できないので、複数日（day_ago）分を特微量に加える必要がある\n",
    "    # 注：tempX[0:day_ago]分は欠如データが生まれる\n",
    "    for s in range(0, num_sihyou): \n",
    "        for i in range(0, day_ago):\n",
    "            tempX[i:len(temp3), day_ago*s+i] = temp3[0:len(temp3)-i,s]\n",
    "             \n",
    "    # 曜日情報の追加\n",
    "    ddata = pd.to_datetime(temp['日付'], format='%Y%m%d')\n",
    "    daydata = ddata[base:len(temp2)].dt.dayofweek\n",
    "    daydata_dummies = pd.get_dummies(daydata, columns=['Yobi'])\n",
    "    daydata2 = np.array(daydata_dummies)\n",
    "    tempX = np.concatenate((tempX, daydata2), axis=1)\n",
    "    \n",
    "    # Xに追加\n",
    "    # X : すべての企業のデータ\n",
    "    # tempX[0:day_ago]分は削除\n",
    "    if reset:\n",
    "        X = tempX[day_ago:]\n",
    "        reset = False\n",
    "    else:\n",
    "        X = np.concatenate((X, tempX[day_ago:]), axis=0)\n",
    "\n",
    "# 何日後を値段の差を予測するのか\n",
    "pre_day = 1\n",
    "# y : pre_day後の終値/当日終値\n",
    "y = np.zeros(len(X))\n",
    "y[0:len(y)-pre_day] = X[pre_day:len(X),0]\n",
    "X = X[:-pre_day]\n",
    "y = y[:-pre_day]\n",
    "\n",
    "up_rate =1.03\n",
    "# y2：翌日の終値/当日の終値がup_rateより上か\n",
    "y2 = np.zeros(len(y))\n",
    "for i in range(0, len(y2)):\n",
    "    if y[i] <= up_rate:\n",
    "        y2[i] = 0\n",
    "    else:\n",
    "        y2[i] = 1\n",
    "\n",
    "# データを一旦分別\n",
    "X_0 = X[y2==0]\n",
    "X_1 = X[y2==1]\n",
    "y_0 = y2[y2==0]\n",
    "y_1 = y2[y2==1]\n",
    "\n",
    "# X_0をX_1とほぼ同じ数にする\n",
    "X_dummy, X_t, y_dummy, y_t = train_test_split(X_0, y_0, test_size=0.09, random_state=0)\n",
    "\n",
    "# 分別したデータの結合\n",
    "X_ = np.concatenate((X_1, X_t), axis=0)\n",
    "y_ = np.concatenate((y_1, y_t))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(\"start time: \", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y_, random_state=0)\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('classifier', MLPClassifier(max_iter=200000, alpha=0.001))])\n",
    "param_grid = {'classifier__hidden_layer_sizes': [(10,), (100,), (500,)]}\n",
    "\n",
    "mlp=MLPClassifier(max_iter=200000, alpha=0.001,random_state=0)\n",
    "mlp.fit(X_train,y_train)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, n_jobs=1, cv=2 ,return_train_score=False, scoring=\"accuracy\")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.cv_results_['mean_test_score'])\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"grid best score, \", grid.best_score_)\n",
    "print(\"Test set score: {:.2f}\".format(grid.score(X_test, y_test)))\n",
    "print(\"over time: \", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "conf = confusion_matrix(y_test, grid.predict(X_test))\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\old2587TimeChart.csv\n",
      "1589\n",
      ".\\old4755TimeChart.csv\n",
      "4395\n",
      ".\\old6022TimeChart.csv\n",
      "4048\n",
      ".\\old6103TimeChart.csv\n",
      "4383\n",
      ".\\old6111TimeChart.csv\n",
      "3485\n",
      ".\\old6113TimeChart.csv\n",
      "4383\n",
      ".\\old6118TimeChart.csv\n",
      "4383\n",
      ".\\old6138TimeChart.csv\n",
      "4375\n",
      ".\\old6143TimeChart.csv\n",
      "4383\n",
      ".\\old6236TimeChart.csv\n",
      "917\n",
      ".\\old6255TimeChart.csv\n",
      "3061\n",
      ".\\old6267TimeChart.csv\n",
      "2717\n",
      ".\\old6282TimeChart.csv\n",
      "4383\n",
      ".\\old6294TimeChart.csv\n",
      "3993\n",
      ".\\old6301TimeChart.csv\n",
      "4383\n",
      ".\\old6328TimeChart.csv\n",
      "4374\n",
      ".\\old6342TimeChart.csv\n",
      "3900\n",
      ".\\old6345TimeChart.csv\n",
      "4383\n",
      ".\\old6362TimeChart.csv\n",
      "4383\n",
      ".\\old6367TimeChart.csv\n",
      "4383\n",
      ".\\old6373TimeChart.csv\n",
      "4383\n",
      ".\\old6383TimeChart.csv\n",
      "4383\n",
      ".\\old6408TimeChart.csv\n",
      "3586\n",
      ".\\old6428TimeChart.csv\n",
      "4382\n",
      ".\\old6430TimeChart.csv\n",
      "4204\n",
      ".\\old6472TimeChart.csv\n",
      "4383\n",
      ".\\old6486TimeChart.csv\n",
      "4380\n",
      ".\\old6494TimeChart.csv\n",
      "4374\n",
      ".\\old6501TimeChart.csv\n",
      "4409\n",
      ".\\old6645TimeChart.csv\n",
      "4406\n",
      ".\\old6752TimeChart.csv\n",
      "4409\n",
      ".\\old6758TimeChart.csv\n",
      "4409\n",
      ".\\old6856TimeChart.csv\n",
      "4406\n",
      ".\\old6861TimeChart.csv\n",
      "4395\n",
      ".\\old7013TimeChart.csv\n",
      "4382\n",
      ".\\old7201TimeChart.csv\n",
      "4395\n",
      ".\\old7203TimeChart.csv\n",
      "4395\n",
      ".\\old7261TimeChart.csv\n",
      "4395\n",
      ".\\old7267TimeChart.csv\n",
      "4395\n",
      ".\\old7701TimeChart.csv\n",
      "4406\n",
      ".\\old7726TimeChart.csv\n",
      "4865\n",
      "X.shape:  (163656, 112)\n",
      "yの割合\n",
      "0 1051\n",
      "1 86302\n",
      "2 51276\n",
      "3 25027\n",
      "[0.52761076 0.50346255 0.48610907]\n",
      "Best parameters:  {'classifier__hidden_layer_sizes': (10,)}\n",
      "grid best score,  0.5276107607827801\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "Test set score: 0.53\n",
      ".\\recent6137TimeChart.csv\n",
      "4719\n",
      "\n",
      "X_recent (112,)\n",
      ".\\recent6231TimeChart.csv\n",
      "455\n",
      "\n",
      "X_recent (2, 112)\n",
      ".\\recent6233TimeChart.csv\n",
      "820\n",
      "\n",
      "X_recent (3, 112)\n",
      ".\\recent6249TimeChart.csv\n",
      "2659\n",
      "\n",
      "X_recent (4, 112)\n",
      ".\\recent6297TimeChart.csv\n",
      "4875\n",
      "\n",
      "X_recent (5, 112)\n",
      ".\\recent6317TimeChart.csv\n",
      "4898\n",
      "\n",
      "X_recent (6, 112)\n",
      ".\\recent6326TimeChart.csv\n",
      "4898\n",
      "\n",
      "X_recent (7, 112)\n",
      ".\\recent6327TimeChart.csv\n",
      "4660\n",
      "\n",
      "X_recent (8, 112)\n",
      ".\\recent6370TimeChart.csv\n",
      "4898\n",
      "\n",
      "X_recent (9, 112)\n",
      ".\\recent6378TimeChart.csv\n",
      "4896\n",
      "\n",
      "X_recent (10, 112)\n",
      ".\\recent6409TimeChart.csv\n",
      "3549\n",
      "\n",
      "X_recent (11, 112)\n",
      ".\\recent6484TimeChart.csv\n",
      "4264\n",
      "\n",
      "X_recent (12, 112)\n",
      ".\\recent6498TimeChart.csv\n",
      "4898\n",
      "\n",
      "X_recent (13, 112)\n",
      ".\\recent7726TimeChart.csv\n",
      "4703\n",
      "\n",
      "X_recent (14, 112)\n",
      "X_predict (14, 112)\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import *\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import mglearn\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "import os\n",
    "import glob\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "files = glob.glob(\"./old*.csv\")\n",
    "\n",
    "# 説明変数となる行列X, 被説明変数となるy2を作成\n",
    "base = 100 \n",
    "day_ago = 7\n",
    "pre_day=1\n",
    "reset =True\n",
    "\n",
    "#出来高やボリンジャーバンドなど指標の数\n",
    "num_sihyou = 16\n",
    "\n",
    "# すべてのCSVファイルから得微量作成\n",
    "for file in files:\n",
    "    temp = pd.read_csv(file, header=0, encoding='cp932')\n",
    "    temp = temp[['日付','始値', '高値','安値','終値','5日平均','25日平均','75日平均','出来高']]\n",
    "    temp= temp.iloc[::-1]#上下反対に\n",
    "    temp2 = np.array(temp)\n",
    "    print(file)\n",
    "    print(len(temp2))\n",
    "    # 前日比を出すためにbase日後からのデータを取得\n",
    "    temp3 = np.zeros((len(temp2)-base, num_sihyou))\n",
    "    temp3[0:len(temp3), 0] = temp2[base:len(temp2), 4].astype(np.float) / temp2[base-1:len(temp2)-1, 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 1] = temp2[base:len(temp2), 1].astype(np.float)/ temp2[base:len(temp2), 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 2] = temp2[base:len(temp2), 2].astype(np.float)/ temp2[base:len(temp2), 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 3] = temp2[base:len(temp2), 3].astype(np.float) / temp2[base:len(temp2), 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 4] = temp2[base:len(temp2), 5].astype(np.float) / temp2[base:len(temp2), 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 5] = temp2[base:len(temp2), 6].astype(np.float) / temp2[base:len(temp2), 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 6] = temp2[base:len(temp2), 7].astype(np.float) / temp2[base:len(temp2), 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 7] = temp2[base:len(temp2), 8].astype(np.float) / temp2[base-1:len(temp2)-1, 8].astype(np.float)\n",
    "    \n",
    "     # 一目均衡表を追加 (9,26, 52) \n",
    "    para1 =9\n",
    "    para2 = 26\n",
    "    para3 = 52\n",
    "    temp2_2 = np.c_[temp2, np.zeros((len(temp2), 3))]\n",
    "    \n",
    "    # 転換線 = （過去(para1)日間の高値 + 安値） ÷ 2\n",
    "    for i in range(para1, len(temp2)):\n",
    "        tmp_high =temp2[i-para1+1:i+1,2].astype(np.float)\n",
    "        tmp_low =temp2[i-para1+1:i+1,3].astype(np.float)\n",
    "        temp2_2[i, 9] = (np.max(tmp_high) + np.min(tmp_low))/2\n",
    "        \n",
    "    temp3[0:len(temp3), 8] = temp2_2[base:len(temp2), 9]/temp2[base:len(temp2), 4]\n",
    "\n",
    "    # 基準線 = （過去(para2)日間の高値 + 安値） ÷ 2\n",
    "    for i in range(para2, len(temp2)):\n",
    "        tmp_high =temp2[i-para2+1:i+1,2].astype(np.float)\n",
    "        tmp_low =temp2[i-para2+1:i+1,3].astype(np.float)\n",
    "        temp2_2[i, 10] = (np.max(tmp_high) + np.min(tmp_low)) / 2\n",
    "    temp3[0:len(temp3), 9] = temp2_2[base:len(temp2), 10]/temp2[base:len(temp2), 4]\n",
    "        \n",
    "    # 先行スパン1 = ｛ （転換値+基準値） ÷ 2 ｝を(para2)日先にずらしたもの\n",
    "    temp3[0:len(temp3), 10] = (temp2_2[base-para2:len(temp2)-para2, 9] + temp2_2[base-para2:len(temp2)-para2, 10]) /2 /temp2[base:len(temp2), 4]\n",
    "\n",
    "    # 先行スパン2 = ｛ （過去(para3)日間の高値+安値） ÷ 2 ｝を(para2)日先にずらしたもの\n",
    "    for i in range(para3, len(temp2)):\n",
    "        tmp_high =temp2[i-para3+1:i+1,2].astype(np.float)\n",
    "        tmp_low =temp2[i-para3+1:i+1,3].astype(np.float)\n",
    "        temp2_2[i, 11] = (np.max(tmp_high) + np.min(tmp_low)) / 2\n",
    "    temp3[0:len(temp3), 11] = temp2_2[base-para2:len(temp2)-para2, 11]/temp2[base:len(temp2), 4]\n",
    "\n",
    "    # 25日ボリンジャーバンド（±1, 2シグマ）を追加\n",
    "    parab = 25\n",
    "    for i in range(base, len(temp2)):\n",
    "        tmp25 = temp2[i-parab+1:i+1,4].astype(np.float)\n",
    "        temp3[i-base,12] = np.mean(tmp25) + 1.0* np.std(tmp25) \n",
    "        temp3[i-base,13] = np.mean(tmp25) - 1.0* np.std(tmp25) \n",
    "        temp3[i-base,14] = np.mean(tmp25) + 2.0* np.std(tmp25) \n",
    "        temp3[i-base,15] = np.mean(tmp25) - 2.0* np.std(tmp25)\n",
    "     \n",
    "    # tempX : 現在の企業のデータ\n",
    "    tempX = np.zeros((len(temp3), day_ago*num_sihyou))\n",
    "    \n",
    "    # 日にちごとに横向きに（day_ago）分並べる\n",
    "    for s in range(0, num_sihyou): \n",
    "        for i in range(0, day_ago):\n",
    "            tempX[i:len(temp3), day_ago*s+i] = temp3[0:len(temp3)-i,s]\n",
    "             \n",
    "    # Xに追加\n",
    "    # X : すべての企業のデータ\n",
    "    if reset:\n",
    "        X = tempX[day_ago:]\n",
    "        reset = False\n",
    "    else:\n",
    "        X = np.concatenate((X, tempX[day_ago:]), axis=0)\n",
    "\n",
    "# y : pre_day後の終値/当日終値\n",
    "y = np.zeros(len(X))\n",
    "y[0:len(y)-pre_day] = X[pre_day:len(X),0]\n",
    "\n",
    "up_rate =1.02\n",
    "down_rate=0.98\n",
    "\n",
    "print(\"X.shape: \", X.shape)\n",
    "print(\"yの割合\")\n",
    "\n",
    "#それぞれの範囲でデータ数をカウント\n",
    "a=b=c=d=0\n",
    "yc = np.zeros(len(y))\n",
    "for i in range(0, len(yc)):\n",
    "    if y[i] <= down_rate:\n",
    "        yc[i] = 0\n",
    "        a+=1\n",
    "    elif y[i]>down_rate and y[i]<=1:\n",
    "        yc[i]=1\n",
    "        b+=1\n",
    "    elif y[i] <=up_rate and y[i]>1:\n",
    "        yc[i] = 2\n",
    "        c+=1\n",
    "    else:\n",
    "        yc[i] = 3\n",
    "        d+=1\n",
    "print(\"0\",a)\n",
    "print(\"1\",b)\n",
    "print(\"2\",c)\n",
    "print(\"3\",d)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, yc, random_state=0)\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('classifier', MLPClassifier(max_iter=200000, alpha=0.001))])\n",
    "param_grid = {'classifier__hidden_layer_sizes': [(10,), (100,), (500,)]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, n_jobs=1, cv=2 ,return_train_score=False, scoring=\"accuracy\")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.cv_results_['mean_test_score'])\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"grid best score, \", grid.best_score_)\n",
    "prediction_test=grid.predict(X_test)\n",
    "print(prediction_test)\n",
    "print(\"Test set score: {:.2f}\".format(grid.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "reset=True\n",
    "#全く違う会社、違う時期のデータで予測\n",
    "files = glob.glob(\"./recent*.csv\")\n",
    "for file in files:\n",
    "    temp = pd.read_csv(file, header=0, encoding='cp932')\n",
    "    temp = temp[['日付','始値', '高値','安値','終値','5日平均','25日平均','75日平均','出来高']]\n",
    "    temp= temp.iloc[::-1]#上下反対に\n",
    "    temp2 = np.array(temp)\n",
    "    print(file)\n",
    "    print(len(temp2))\n",
    "    # 前日比を出すためにbase日後からのデータを取得\n",
    "    temp3 = np.zeros((len(temp2)-base, num_sihyou))\n",
    "    temp3[0:len(temp3), 0] = temp2[base:len(temp2), 4].astype(np.float) / temp2[base-1:len(temp2)-1, 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 1] = temp2[base:len(temp2), 1].astype(np.float)/ temp2[base:len(temp2), 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 2] = temp2[base:len(temp2), 2].astype(np.float)/ temp2[base:len(temp2), 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 3] = temp2[base:len(temp2), 3].astype(np.float) / temp2[base:len(temp2), 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 4] = temp2[base:len(temp2), 5].astype(np.float) / temp2[base:len(temp2), 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 5] = temp2[base:len(temp2), 6].astype(np.float) / temp2[base:len(temp2), 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 6] = temp2[base:len(temp2), 7].astype(np.float) / temp2[base:len(temp2), 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 7] = temp2[base:len(temp2), 8].astype(np.float) / temp2[base-1:len(temp2)-1, 8].astype(np.float)\n",
    "    \n",
    "     # 一目均衡表を追加 (9,26, 52) \n",
    "    para1 =9\n",
    "    para2 = 26\n",
    "    para3 = 52\n",
    "    temp2_2 = np.c_[temp2, np.zeros((len(temp2), 3))]\n",
    "    \n",
    "    # 転換線 = （過去(para1)日間の高値 + 安値） ÷ 2\n",
    "    for i in range(para1, len(temp2)):\n",
    "        tmp_high =temp2[i-para1+1:i+1,2].astype(np.float)\n",
    "        tmp_low =temp2[i-para1+1:i+1,3].astype(np.float)\n",
    "        temp2_2[i, 9] = (np.max(tmp_high) + np.min(tmp_low))/2\n",
    "        \n",
    "    temp3[0:len(temp3), 8] = temp2_2[base:len(temp2), 9]/temp2[base:len(temp2), 4]\n",
    "\n",
    "    # 基準線 = （過去(para2)日間の高値 + 安値） ÷ 2\n",
    "    for i in range(para2, len(temp2)):\n",
    "        tmp_high =temp2[i-para2+1:i+1,2].astype(np.float)\n",
    "        tmp_low =temp2[i-para2+1:i+1,3].astype(np.float)\n",
    "        temp2_2[i, 10] = (np.max(tmp_high) + np.min(tmp_low)) / 2\n",
    "    temp3[0:len(temp3), 9] = temp2_2[base:len(temp2), 10]/temp2[base:len(temp2), 4]\n",
    "        \n",
    "    # 先行スパン1 = ｛ （転換値+基準値） ÷ 2 ｝を(para2)日先にずらしたもの\n",
    "    temp3[0:len(temp3), 10] = (temp2_2[base-para2:len(temp2)-para2, 9] + temp2_2[base-para2:len(temp2)-para2, 10]) /2 /temp2[base:len(temp2), 4]\n",
    "\n",
    "    # 先行スパン2 = ｛ （過去(para3)日間の高値+安値） ÷ 2 ｝を(para2)日先にずらしたもの\n",
    "    for i in range(para3, len(temp2)):\n",
    "        tmp_high =temp2[i-para3+1:i+1,2].astype(np.float)\n",
    "        tmp_low =temp2[i-para3+1:i+1,3].astype(np.float)\n",
    "        temp2_2[i, 11] = (np.max(tmp_high) + np.min(tmp_low)) / 2\n",
    "    temp3[0:len(temp3), 11] = temp2_2[base-para2:len(temp2)-para2, 11]/temp2[base:len(temp2), 4]\n",
    "\n",
    "    # 25日ボリンジャーバンド（±1, 2シグマ）を追加\n",
    "    parab = 25\n",
    "    for i in range(base, len(temp2)):\n",
    "        tmp25 = temp2[i-parab+1:i+1,4].astype(np.float)\n",
    "        temp3[i-base,12] = np.mean(tmp25) + 1.0* np.std(tmp25) \n",
    "        temp3[i-base,13] = np.mean(tmp25) - 1.0* np.std(tmp25) \n",
    "        temp3[i-base,14] = np.mean(tmp25) + 2.0* np.std(tmp25) \n",
    "        temp3[i-base,15] = np.mean(tmp25) - 2.0* np.std(tmp25)\n",
    "     \n",
    "    # tempX : 現在の企業のデータ\n",
    "    tempX = np.zeros((len(temp3), day_ago*num_sihyou))\n",
    "    \n",
    "    # 日にちごとに横向きに（day_ago）分並べる\n",
    "    for s in range(0, num_sihyou): \n",
    "        for i in range(0, day_ago):\n",
    "            tempX[i:len(temp3), day_ago*s+i] = temp3[0:len(temp3)-i,s]\n",
    "    print()\n",
    "    # Xに追加\n",
    "    # X : すべての企業のデータ\n",
    "    \n",
    "    if reset:\n",
    "        X_recent = tempX[len(temp3)-1,:]\n",
    "        reset = False\n",
    "    else:\n",
    "        X_recent = np.vstack((X_recent, tempX[len(temp3)-1,:]))\n",
    "    print(\"X_recent\",X_recent.shape)\n",
    "print(\"X_predict\",X_recent.shape)\n",
    "prediction=grid.predict(X_recent)\n",
    "print(prediction)\n",
    "print(len(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20220214 519 525 ... '     521.56' '      542.6' 1600]\n",
      " [20220210 527 529 ... '     522.32' '     543.73' 1600]\n",
      " [20220209 520 529 ... '     522.96' '     544.62' 1100]\n",
      " ...\n",
      " [20181001 854 854 ... '         --' '         --' 32400]\n",
      " [20180928 704 704 ... '         --' '         --' 83900]\n",
      " [20180927 696 699 ... '         --' '         --' 2957100]]\n",
      "-----------------------\n",
      "[[20180927 696 699 ... '         --' '         --' 2957100]\n",
      " [20180928 704 704 ... '         --' '         --' 83900]\n",
      " [20181001 854 854 ... '         --' '         --' 32400]\n",
      " ...\n",
      " [20220209 520 529 ... '     522.96' '     544.62' 1100]\n",
      " [20220210 527 529 ... '     522.32' '     543.73' 1600]\n",
      " [20220214 519 525 ... '     521.56' '      542.6' 1600]]\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(\"./recent6297.csv\")\n",
    "temp = pd.read_csv(file, header=0, encoding='cp932')\n",
    "temp = temp[['日付','始値', '高値','安値','終値','5日平均','25日平均','75日平均','出来高']]\n",
    "#print(temp)\n",
    "temp2 = np.array(temp)\n",
    "print(temp2)\n",
    "temp= temp.iloc[::-1]#上下反対に\n",
    "print(\"-----------------------\")\n",
    "\n",
    "temp2_new = np.array(temp)\n",
    "print(temp2_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import *\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import mglearn\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "import os\n",
    "import glob\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "files = glob.glob(\"./*.csv\")\n",
    "\n",
    "# 説明変数となる行列X, 被説明変数となるy2を作成\n",
    "base = 100 \n",
    "day_ago = 15\n",
    "pre_day=1\n",
    "reset =True\n",
    "\n",
    "#出来高やボリンジャーバンドなど指標の数\n",
    "num_sihyou = 16\n",
    "\n",
    "# すべてのCSVファイルから得微量作成\n",
    "for file in files:\n",
    "    temp = pd.read_csv(file, header=0, encoding='cp932')\n",
    "    temp = temp[['日付','始値', '高値','安値','終値','5日平均','25日平均','75日平均','出来高']]\n",
    "    temp= temp.iloc[::-1]#上下反対に\n",
    "    temp2 = np.array(temp)\n",
    "    \n",
    "    # 前日比を出すためにbase日後からのデータを取得\n",
    "    temp3 = np.zeros((len(temp2)-base, num_sihyou))\n",
    "    temp3[0:len(temp3), 0] = temp2[base:len(temp2), 4].astype(np.float) / temp2[base-1:len(temp2)-1, 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 1] = temp2[base:len(temp2), 1].astype(np.float)/ temp2[base:len(temp2), 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 2] = temp2[base:len(temp2), 2].astype(np.float)/ temp2[base:len(temp2), 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 3] = temp2[base:len(temp2), 3].astype(np.float) / temp2[base:len(temp2), 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 4] = temp2[base:len(temp2), 5].astype(np.float) / temp2[base:len(temp2), 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 5] = temp2[base:len(temp2), 6].astype(np.float) / temp2[base:len(temp2), 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 6] = temp2[base:len(temp2), 7].astype(np.float) / temp2[base:len(temp2), 4].astype(np.float)\n",
    "    temp3[0:len(temp3), 7] = temp2[base:len(temp2), 8].astype(np.float) / temp2[base-1:len(temp2)-1, 8].astype(np.float)\n",
    "    \n",
    "     # 一目均衡表を追加 (9,26, 52) \n",
    "    para1 =9\n",
    "    para2 = 26\n",
    "    para3 = 52\n",
    "    temp2_2 = np.c_[temp2, np.zeros((len(temp2), 3))]\n",
    "    \n",
    "    # 転換線 = （過去(para1)日間の高値 + 安値） ÷ 2\n",
    "    for i in range(para1, len(temp2)):\n",
    "        tmp_high =temp2[i-para1+1:i+1,2].astype(np.float)\n",
    "        tmp_low =temp2[i-para1+1:i+1,3].astype(np.float)\n",
    "        temp2_2[i, 9] = (np.max(tmp_high) + np.min(tmp_low))/2\n",
    "        \n",
    "    temp3[0:len(temp3), 8] = temp2_2[base:len(temp2), 9]/temp2[base:len(temp2), 4]\n",
    "\n",
    "    # 基準線 = （過去(para2)日間の高値 + 安値） ÷ 2\n",
    "    for i in range(para2, len(temp2)):\n",
    "        tmp_high =temp2[i-para2+1:i+1,2].astype(np.float)\n",
    "        tmp_low =temp2[i-para2+1:i+1,3].astype(np.float)\n",
    "        temp2_2[i, 10] = (np.max(tmp_high) + np.min(tmp_low)) / 2\n",
    "    temp3[0:len(temp3), 9] = temp2_2[base:len(temp2), 10]/temp2[base:len(temp2), 4]\n",
    "        \n",
    "    # 先行スパン1 = ｛ （転換値+基準値） ÷ 2 ｝を(para2)日先にずらしたもの\n",
    "    temp3[0:len(temp3), 10] = (temp2_2[base-para2:len(temp2)-para2, 9] + temp2_2[base-para2:len(temp2)-para2, 10]) /2 /temp2[base:len(temp2), 4]\n",
    "\n",
    "    # 先行スパン2 = ｛ （過去(para3)日間の高値+安値） ÷ 2 ｝を(para2)日先にずらしたもの\n",
    "    for i in range(para3, len(temp2)):\n",
    "        tmp_high =temp2[i-para3+1:i+1,2].astype(np.float)\n",
    "        tmp_low =temp2[i-para3+1:i+1,3].astype(np.float)\n",
    "        temp2_2[i, 11] = (np.max(tmp_high) + np.min(tmp_low)) / 2\n",
    "    temp3[0:len(temp3), 11] = temp2_2[base-para2:len(temp2)-para2, 11]/temp2[base:len(temp2), 4]\n",
    "\n",
    "    # 25日ボリンジャーバンド（±1, 2シグマ）を追加\n",
    "    parab = 25\n",
    "    for i in range(base, len(temp2)):\n",
    "        tmp25 = temp2[i-parab+1:i+1,4].astype(np.float)\n",
    "        temp3[i-base,12] = np.mean(tmp25) + 1.0* np.std(tmp25) \n",
    "        temp3[i-base,13] = np.mean(tmp25) - 1.0* np.std(tmp25) \n",
    "        temp3[i-base,14] = np.mean(tmp25) + 2.0* np.std(tmp25) \n",
    "        temp3[i-base,15] = np.mean(tmp25) - 2.0* np.std(tmp25)\n",
    "     \n",
    "    # tempX : 現在の企業のデータ\n",
    "    tempX = np.zeros((len(temp3), day_ago*num_sihyou))\n",
    "    \n",
    "    # 日にちごとに横向きに（day_ago）分並べる\n",
    "    for s in range(0, num_sihyou): \n",
    "        for i in range(0, day_ago):\n",
    "            tempX[i:len(temp3), day_ago*s+i] = temp3[0:len(temp3)-i,s]\n",
    "             \n",
    "    # Xに追加\n",
    "    # X : すべての企業のデータ\n",
    "    if reset:\n",
    "        X = tempX[day_ago:]\n",
    "        reset = False\n",
    "    else:\n",
    "        X = np.concatenate((X, tempX[day_ago:]), axis=0)\n",
    "        \n",
    "up_rate =1.0\n",
    "# y : pre_day後の終値/当日終値\n",
    "y = np.zeros(len(X))\n",
    "y[0:len(y)-pre_day] = X[pre_day:len(X),0]\n",
    "\n",
    "\n",
    "#それぞれの範囲でデータ数をカウント\n",
    "a=b=0\n",
    "yc = np.zeros(len(y))\n",
    "for i in range(0, len(yc)):\n",
    "    if y[i]>up_rate:\n",
    "        yc[i]=1\n",
    "        a+=1\n",
    "    else :\n",
    "        yc[i] = 0\n",
    "        b+=1\n",
    "print(\"0\",a)\n",
    "print(\"1\",b)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, yc, random_state=0)\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('classifier', MLPClassifier(max_iter=200000, alpha=0.001))])\n",
    "param_grid = {'classifier__hidden_layer_sizes': [(10,), (100,), (500,)]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, n_jobs=1, cv=2 ,return_train_score=False, scoring=\"f1\")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.cv_results_['mean_test_score'])\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"grid best score, \", grid.best_score_)\n",
    "print(\"Test set score: {:.2f}\".format(grid.score(X_test, y_test)))\n",
    "\n",
    "conf = confusion_matrix(y_test, grid.predict(X_test))\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
